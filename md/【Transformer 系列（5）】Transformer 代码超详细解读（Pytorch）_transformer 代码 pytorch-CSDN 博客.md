> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [blog.csdn.net](https://blog.csdn.net/weixin_43334693/article/details/130313746)

![](https://img-blog.csdnimg.cn/0a64a64e43b14ac0a0c86d30d5b3e78a.jpeg)

å‰è¨€Â 
---

å‰é¢å‡ ç¯‡æˆ‘ä»¬ä¸€èµ·è¯»äº† [transformer](https://so.csdn.net/so/search?q=transformer&spm=1001.2101.3001.7020) çš„è®ºæ–‡ï¼Œæ›´è¿›ä¸€æ­¥äº†è§£äº†å®ƒçš„æ¨¡å‹æ¶æ„ï¼Œè¿™ä¸€ç¯‡å‘¢ï¼Œæˆ‘ä»¬å°±æ¥çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•ä»£ç å®ç°çš„ï¼

![](https://img-blog.csdnimg.cn/9566daf425834f23a0ea03637057ff4d.png)

ï¼ˆå»ºè®®å¤§å®¶åœ¨è¯»è¿™ä¸€ç¯‡ä¹‹å‰ï¼Œå…ˆå»çœ‹çœ‹ä¸Šä¸€ç¯‡[æ¨¡å‹ç»“æ„è®²è§£](https://blog.csdn.net/weixin_43334693/article/details/130250571?spm=1001.2014.3001.5501 "æ¨¡å‹ç»“æ„è®²è§£Â ") Â è¿™æ ·å¯ä»¥ç†è§£æ›´æ·±åˆ»å™¢ï¼ï¼‰

transformer ä»£ç æœ‰å¾ˆå¤šç‰ˆæœ¬ï¼Œæœ¬æ–‡æ˜¯å‚è€ƒ B ç«™[è¿™ä½å¤§ä½¬](https://www.bilibili.com/video/BV1dR4y1E7aL/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=31a0246bd070fa6719bbec1ba2154865 "è¿™ä½å¤§ä½¬")æ”¹è¿›åçš„ä»£ç è¿›è¡Œè§£è¯»ï¼Œå› ä¸ºæˆ‘ä¹Ÿæ˜¯åˆšå¼€å§‹å­¦ä¹ ï¼Œèƒ½åŠ›æœ‰é™ï¼Œå¦‚æœ‰ä¸è¯¦å®ä¹‹å¤„ï¼Œå¤§å®¶å¯ç§»æ­¥è‡³æ–‡æœ«çš„ä¼ é€é—¨å»çœ‹å¤§ä½¬è§£è¯»çš„æ›´å¤šç»†èŠ‚å—·~

![](https://img-blog.csdnimg.cn/f5f7feb7e99b4a3295d4f6f71505cc94.gif)

![](https://img-blog.csdnimg.cn/962f7cb1b48f44e29d9beb1d499d0530.gif)â€‹Â  Â ğŸ€**å‰æœŸå›é¡¾**

Â [ã€Transformer ç³»åˆ—ï¼ˆ1ï¼‰ã€‘encoderï¼ˆç¼–ç å™¨ï¼‰å’Œ decoderï¼ˆè§£ç å™¨ï¼‰](https://blog.csdn.net/weixin_43334693/article/details/130161845?spm=1001.2014.3001.5502 "ã€Transformerç³»åˆ—ï¼ˆ1ï¼‰ã€‘encoderï¼ˆç¼–ç å™¨ï¼‰å’Œdecoderï¼ˆè§£ç å™¨ï¼‰")

[ã€Transformer ç³»åˆ—ï¼ˆ2ï¼‰ã€‘æ³¨æ„åŠ›æœºåˆ¶ã€è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€é€šé“æ³¨æ„åŠ›æœºåˆ¶ã€ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶è¶…è¯¦ç»†è®²è§£](https://blog.csdn.net/weixin_43334693/article/details/130189238?spm=1001.2014.3001.5502 "ã€Transformerç³»åˆ—ï¼ˆ2ï¼‰ã€‘æ³¨æ„åŠ›æœºåˆ¶ã€è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€é€šé“æ³¨æ„åŠ›æœºåˆ¶ã€ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶è¶…è¯¦ç»†è®²è§£")  
[ã€Transformer ç³»åˆ—ï¼ˆ3ï¼‰ã€‘ã€ŠAttention Is All You Needã€‹è®ºæ–‡è¶…è¯¦ç»†è§£è¯»ï¼ˆç¿»è¯‘ï¼‹ç²¾è¯»ï¼‰](https://blog.csdn.net/weixin_43334693/article/details/130208816?spm=1001.2014.3001.5502 "ã€Transformerç³»åˆ—ï¼ˆ3ï¼‰ã€‘ã€ŠAttention Is All You Needã€‹è®ºæ–‡è¶…è¯¦ç»†è§£è¯»ï¼ˆç¿»è¯‘ï¼‹ç²¾è¯»ï¼‰")  
[ã€Transformer ç³»åˆ—ï¼ˆ4ï¼‰ã€‘Transformer æ¨¡å‹ç»“æ„è¶…è¯¦ç»†è§£è¯»](https://blog.csdn.net/weixin_43334693/article/details/130250571?spm=1001.2014.3001.5501 "ã€Transformerç³»åˆ—ï¼ˆ4ï¼‰ã€‘Transformeræ¨¡å‹ç»“æ„è¶…è¯¦ç»†è§£è¯»")

**ç›®å½•**

[å‰è¨€](#t1) 

[ğŸš€0. å¯¼å…¥ä¾èµ–åº“](#t2)

[ğŸš€1. æ•°æ®é¢„å¤„ç†](#t3) 

[1.1 æ•°æ®å‡†å¤‡](#t4)

[1.1.1 è®­ç»ƒé›†ï¼šå¥å­è¾“å…¥éƒ¨åˆ†](#t5)

[1.1.2 æµ‹è¯•é›†ï¼šæ„å»ºè¯è¡¨](#t6)

[1.2 æ•°æ®æ„å»º](#t7) 

[1.2.1Â å®ç°ä¸€ä¸ª minibatch è¿­ä»£å™¨](#t8)

[1.2.2Â è‡ªå®šä¹‰ä¸€ä¸ª MyDataSet å»è¯»å–è¿™äº›å¥å­](#t9)

[ğŸš€2. æ¨¡å‹æ•´ä½“æ¶æ„](#t10)

[2.1 è¶…å‚æ•°è®¾ç½®](#t11)

[2.2 æ•´ä½“æ¶æ„](#t12)

[2.3 æ¨¡å‹è®­ç»ƒ](#t13)

[ğŸš€3. ç¼–ç å™¨ï¼ˆEncoderï¼‰](#t14)

[3.1 Encoder Layerï¼šå•ä¸ªç¼–ç å™¨å±‚](#t15)

[3.2 Encoderï¼šç¼–ç å™¨](#t16)

[3.3 Padding Maskï¼šå½¢æˆä¸€ä¸ªç¬¦å·çŸ©é˜µ](#t17)

[ğŸš€4. è§£ç å™¨ï¼ˆDecoderï¼‰](#t18)

[4.1Decoder Layerï¼šå•ä¸ªè§£ç å±‚](#t19) 

[4.2Decoderï¼šè§£ç å™¨](#t20)

[4.3 Sequence Maskï¼šå±è”½å­åºåˆ—çš„ mask](#t21)

[ğŸš€5. ä½ç½®ç¼–ç ï¼ˆPosition Embeddingï¼‰](#t22)

[ğŸš€6. æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰](#t23)

[6.1Scaled DotProduct Attentionï¼šç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶](#t24)

[6.2MultiHead Attentionï¼šå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶](#t25)

[ğŸš€7. å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆPoswiseFeedForwardï¼‰](#t26)

Â  Â  Â  Â  Â Â [7.1 å®ç°æ–¹å¼ 1ï¼šConv1d](#7.1%20%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F1%EF%BC%9AConv1d)

 [7.2 å®ç°æ–¹å¼ 2ï¼šLinear](#t27)

![](https://img-blog.csdnimg.cn/349c1282ff7546ecab74c7a0978db491.gif)

ğŸš€0. å¯¼å…¥ä¾èµ–åº“
----------

```
#======================0.å¯¼å…¥ä¾èµ–åº“=============================#
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import math
```

*   **numpyï¼š**Â Â ç§‘å­¦è®¡ç®—åº“ï¼Œæä¾›äº†çŸ©é˜µï¼Œçº¿æ€§ä»£æ•°ï¼Œå‚…ç«‹å¶å˜æ¢ç­‰ç­‰çš„è§£å†³æ–¹æ¡ˆ, æœ€å¸¸ç”¨çš„æ˜¯å®ƒçš„ N ç»´æ•°ç»„å¯¹è±¡
*   **torchï¼š** è¿™æ˜¯ä¸»è¦çš„ Pytorch åº“ã€‚å®ƒæä¾›äº†æ„å»ºã€è®­ç»ƒå’Œè¯„ä¼°ç¥ç»ç½‘ç»œçš„å·¥å…·
*   **torch.nnï¼š**Â Â torch ä¸‹åŒ…å«ç”¨äºæ­å»ºç¥ç»ç½‘ç»œçš„ modules å’Œå¯ç”¨äºç»§æ‰¿çš„ç±»çš„ä¸€ä¸ªå­åŒ…
*   **torch.optimï¼š**Â Â ä¼˜åŒ–å™¨ Optimizerã€‚ä¸»è¦æ˜¯åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µå¯¹æ¨¡å‹å¯å­¦ä¹ å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œå¸¸ç”¨ä¼˜åŒ–å™¨æœ‰ SGDï¼ŒRMSpropï¼ŒAdam ç­‰
*   **matplotlib.pyplotï¼š**Â Â matplotlib.pyplotÂ æ˜¯ä¸€ä¸ªå‘½ä»¤å‹å‡½æ•°é›†åˆï¼Œå®ƒå¯ä»¥åƒä½¿ç”¨Â MatlabÂ ä¸€æ ·ä½¿ç”¨Â matplotlibï¼ŒpyplotÂ ä¸­çš„æ¯ä¸€ä¸ªå‡½æ•°éƒ½ä¼šå¯¹ç”»å¸ƒå›¾åƒä½œå‡ºç›¸åº”çš„æ”¹å˜
*   **mathï¼š**Â Â è°ƒç”¨è¿™ä¸ªåº“è¿›è¡Œæ•°å­¦è¿ç®—

ğŸš€1. æ•°æ®é¢„å¤„ç†Â 
-----------

æœ¬æ–‡ä»¥ä¸€ä¸ªç®€å•çš„**å¾·è¯­åˆ°è‹±è¯­**çš„**æœºå™¨ç¿»è¯‘**ä»»åŠ¡ Demo ä¸ºä¾‹ã€‚

### 1.1 æ•°æ®å‡†å¤‡

#### **1.1.1 è®­ç»ƒé›†ï¼šå¥å­è¾“å…¥éƒ¨åˆ†**

```
# ===1.è®­ç»ƒé›†ï¼ˆå¥å­è¾“å…¥éƒ¨åˆ†ï¼‰===#
    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']
```

*   ç¬¬ä¸€ä¸ªå¾·è¯­å¥å­ 'ich mochte ein bier P'Â  --> **ç¼–ç ç«¯çš„è¾“å…¥**
*   ç¬¬äºŒä¸ªè‹±è¯­å¥å­Â 'S i want a beer' --> **è§£ç ç«¯çš„è¾“å…¥**
*   ç¬¬ä¸‰ä¸ªè‹±è¯­å¥å­Â 'i want a beer E' --> **è§£ç ç«¯çš„çœŸå®æ ‡ç­¾ï¼ˆç­”æ¡ˆï¼‰**

å¯ä»¥é€šè¿‡è¿™ä¸ªå›¾æ¥ç†è§£ä¸€ä¸‹ï¼š

![](https://img-blog.csdnimg.cn/c49e1526a6b04eeca62a63728343dc33.png)

> Pã€Sã€E æ˜¯ä»€ä¹ˆï¼Ÿ
> 
> *   **Pï¼š**pad å­—ç¬¦ã€‚å¦‚æœå½“å‰æ‰¹æ¬¡çš„æ•°æ®é‡å°äºæ—¶é—´æ­¥æ•°ï¼Œå°†å¡«å†™ç©ºç™½åºåˆ—çš„ç¬¦å·ã€‚
> *   **Sï¼š**Startã€‚æ˜¾ç¤º è§£ç  è¾“å…¥å¼€å§‹ çš„ç¬¦å·Â 
> *   **Eï¼š**Endã€‚æ˜¾ç¤º è§£ç  è¾“å‡ºå¼€å§‹ çš„ç¬¦å·

#### **1.1.2 æµ‹è¯•é›†ï¼šæ„å»ºè¯è¡¨**

```
#===2.æµ‹è¯•é›†ï¼ˆæ„å»ºè¯è¡¨ï¼‰===#
    
    # ç¼–ç ç«¯çš„è¯è¡¨
    src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4}
    src_vocab_size = len(src_vocab)  # src_vocab_sizeï¼šå®é™…æƒ…å†µä¸‹ï¼Œå®ƒçš„é•¿åº¦åº”è¯¥æ˜¯æ‰€æœ‰å¾·è¯­å•è¯çš„ä¸ªæ•°
 
    # è§£ç ç«¯çš„è¯è¡¨
    tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6}
    tgt_vocab_size = len(tgt_vocab)  # å®é™…æƒ…å†µä¸‹ï¼Œå®ƒåº”è¯¥æ˜¯æ‰€æœ‰è‹±è¯­å•è¯ä¸ªæ•°
```

è¯åµŒå…¥æœ¬èº«æ˜¯ä¸€ä¸ª look up æŸ¥è¡¨çš„è¿‡ç¨‹ï¼Œå› æ­¤éœ€è¦æ„å»ºè¯è¡¨ï¼štoken åŠå…¶ç´¢å¼•ã€‚

ç°åœ¨çš„å®é™…ä»»åŠ¡ä¸­ï¼Œä¸€èˆ¬ä½¿ç”¨ Huggingface Transformers åº“çš„ Tokenizer ç­‰ API ç›´æ¥è·å–ã€‚

å…¶å®ç¼–ç ç«¯å’Œè§£ç ç«¯å¯ä»¥å…±ç”¨ä¸€ä¸ªè¯è¡¨çš„ã€‚

### **1.2 æ•°æ®æ„å»º** 

#### **1.2.1Â å®ç°ä¸€ä¸ª minibatch è¿­ä»£å™¨**

```
def make_batch(sentences):
    input_batch = [[src_vocab[n] for n in sentences[0].split()]] # è¾“å…¥æ•°æ®é›†
    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]] # è¾“å‡ºæ•°æ®é›†
    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]] # ç›®æ ‡æ•°æ®é›†
    return torch.LongTensor(input_batch), torch.LongTensor(output_batch), torch.LongTensor(target_batch)
```

è¿™æ®µä»£ç ä¸»è¦æ˜¯æŠŠå­—ç¬¦ä¸²ç±»å‹çš„æ–‡æœ¬è½¬æˆè¯è¡¨ç´¢å¼•ï¼Œç„¶åå†æŠŠç´¢å¼•è½¬æˆ tensor ç±»å‹ã€‚

#### **1.2.2** è‡ªå®šä¹‰ä¸€ä¸ª MyDataSet å»è¯»å–è¿™äº›å¥å­

```
â€‹ class MyDataSet(Data.Dataset):
     """è‡ªå®šä¹‰DataLoader"""
 â€‹
     def __init__(self, enc_inputs, dec_inputs, dec_outputs):
         super(MyDataSet, self).__init__()
         self.enc_inputs = enc_inputs
         self.dec_inputs = dec_inputs
         self.dec_outputs = dec_outputs
 â€‹
     def __len__(self):
         return self.enc_inputs.shape[0]
 â€‹
     def __getitem__(self, idx):
         return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]
 â€‹
 â€‹
 loader = Data.DataLoader(
     MyDataSet(enc_inputs, dec_inputs, dec_outputs), 2, True)
```

Â æˆ‘ä»¬éœ€è¦åœ¨è‡ªå®šä¹‰çš„æ•°æ®é›†ç±»ä¸­ç»§æ‰¿ Dataset ç±»ï¼ŒåŒæ—¶è¿˜éœ€è¦å®ç°ä¸¤ä¸ªæ–¹æ³•ï¼š

*   **__len__æ–¹æ³•ï¼š**Â  èƒ½å¤Ÿå®ç°é€šè¿‡å…¨å±€çš„ len() Â æ–¹æ³•è·å–å…¶ä¸­çš„å…ƒç´ ä¸ªæ•°
*   **__getitem__æ–¹æ³•ï¼š**Â  èƒ½å¤Ÿé€šè¿‡ä¼ å…¥ç´¢å¼•çš„æ–¹å¼è·å–æ•°æ®ï¼Œä¾‹å¦‚é€šè¿‡ dataset[i] Â è·å–å…¶ä¸­çš„ç¬¬ i æ¡æ•°æ®

æœ€å DataLoader è¿›è¡Œå°è£…ï¼šdatasetï¼Œbatch_sizeï¼Œshuffle(æ˜¯å¦æ‰“ä¹±)

ğŸš€2. æ¨¡å‹æ•´ä½“æ¶æ„
-----------

### 2.1 è¶…å‚æ•°è®¾ç½®

```
src_len = 5 # length of source ç¼–ç ç«¯çš„è¾“å…¥é•¿åº¦
    tgt_len = 5 # length of target è§£ç ç«¯çš„è¾“å…¥é•¿åº¦
 
    #===Transformerå‚æ•°===#
    d_model = 512  # Embedding Size æ¯ä¸€ä¸ªå­—ç¬¦è½¬åŒ–æˆEmbeddingçš„å¤§å°
    d_ff = 2048  # FeedForward dimension å‰é¦ˆç¥ç»ç½‘ç»œæ˜ å°„åˆ°å¤šå°‘ç»´åº¦
    d_k = d_v = 64  # dimension of K(=Q), V
    n_layers = 6  # number of Encoder of Decoder Layer  encoderå’Œdecoderçš„ä¸ªæ•°ï¼Œè¿™ä¸ªè®¾ç½®çš„æ˜¯6ä¸ªencoderå’Œdecoderå †å åœ¨ä¸€èµ·ï¼ˆencoderå’Œdecoderçš„ä¸ªæ•°å¿…é¡»ä¿æŒä¸€æ ·å—ï¼‰
    n_heads = 8  # number of heads in Multi-Head Attention  å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ—¶ï¼ŒæŠŠå¤´åˆ†ä¸ºå‡ ä¸ªï¼Œè¿™é‡Œè¯´çš„æ˜¯åˆ†ä¸º8ä¸ª
```

**é‡è¦å‚æ•°ï¼š**

*   **src_len ï¼š**Â  ç¼–ç ç«¯çš„è¾“å…¥é•¿åº¦
*   **tgt_len ï¼šÂ ** Â è§£ç ç«¯çš„è¾“å…¥é•¿åº¦
*   **d_modelï¼š** éœ€è¦å®šä¹‰ embeding çš„ç»´åº¦ï¼Œè®ºæ–‡ä¸­è®¾ç½®çš„ 512
*   **d_ffï¼š** FeedForward å±‚éšè—ç¥ç»å…ƒä¸ªæ•°ï¼Œè®ºæ–‡ä¸­è®¾ç½®çš„ 2048
*   **d_k = d_vï¼š** Qã€Kã€V å‘é‡çš„ç»´åº¦ï¼Œå…¶ä¸­ Q ä¸ K çš„ç»´åº¦å¿…é¡»ç›¸ç­‰ï¼ŒV çš„ç»´åº¦æ²¡æœ‰é™åˆ¶ï¼Œéƒ½è®¾ä¸º 64
*   **n_layersï¼š**Â Â Encoder å’Œ Decoder çš„ä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯å›¾ä¸­çš„ Nx
*   **n_headsï¼š** å¤šå¤´æ³¨æ„åŠ›ä¸­ head çš„æ•°é‡

### 2.2 æ•´ä½“æ¶æ„

```
class Transformer(nn.Module):
    def __init__(self):
        super(Transformer, self).__init__()
        self.encoder=Encoder().to(device) # ç¼–ç å±‚
        self.decoder=Decoder().to(device) # è§£ç å±‚
       # è¾“å‡ºå±‚ï¼Œd_modelæ˜¯è§£ç å±‚æ¯ä¸€ä¸ªtokenè¾“å‡ºç»´åº¦çš„å¤§å°ï¼Œä¹‹åä¼šåšä¸€ä¸ªtgt_vocab_sizeå¤§å°çš„softmax
        self.projection=nn.Linear(d_model,tgt_vocab_size,bias=False).to(device)
    
    # å®ç°å‡½æ•°
    def forward(self, enc_inputs,dec_inputs):
        """
         Transformersçš„è¾“å…¥ï¼šä¸¤ä¸ªåºåˆ—ï¼ˆç¼–ç ç«¯çš„è¾“å…¥ï¼Œè§£ç ç«¯çš„è¾“å…¥ï¼‰
         enc_inputs: [batch_size, src_len]   å½¢çŠ¶ï¼šbatch_sizeä¹˜src_len
         dec_inputs: [batch_size, tgt_len]   å½¢çŠ¶ï¼šbatch_sizeä¹˜tgt_len
         """
        # tensor to store decoder outputs
        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)
 
        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]
        # ç»è¿‡Encoderç½‘ç»œåï¼Œå¾—åˆ°çš„è¾“å‡ºè¿˜æ˜¯[batch_size, src_len, d_model]
        enc_outputs,enc_self_attns=self.encoder(enc_inputs)
 
        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]
        dec_outputs,dec_self_attns,dec_enc_attns=self.decoder(dec_inputs,enc_inputs,enc_outputs)
 
        # dec_outputs: [batch_size, tgt_len, d_model] -> dec_logits: [batch_size, tgt_len, tgt_vocab_size]
        dec_logits=self.projection(dec_outputs)
        return dec_logits.view(-1,dec_logits.size(-1)),enc_self_attns,dec_self_attns,dec_enc_attns
```

Transformer ä¸»è¦å°±æ˜¯**è°ƒç”¨ Encoder å’Œ Decoder**ã€‚æœ€åè¿”å› dec_logits çš„ç»´åº¦æ˜¯ **[batch_size * tgt_len, tgt_vocab_size]**ã€‚

**ä¸»è¦æµç¨‹ï¼š**

*   è¾“å…¥æ–‡æœ¬è¿›è¡Œè¯åµŒå…¥å’Œä½ç½®ç¼–ç ï¼Œä½œä¸ºæœ€ç»ˆçš„æ–‡æœ¬åµŒå…¥ï¼›
*   æ–‡æœ¬åµŒå…¥ç»è¿‡ Encoder ç¼–ç ï¼Œå¾—åˆ°æ³¨æ„åŠ›åŠ æƒåè¾“å‡ºçš„ç¼–ç å‘é‡ä»¥åŠè‡ªæ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼›
*   ç„¶åå°†ç¼–ç å‘é‡å’Œæ ·æœ¬çš„ Ground trurh å…±åŒè¾“å…¥è§£ç å™¨ï¼Œç»è¿‡æ³¨æ„åŠ›åŠ æƒç­‰æ“ä½œåè¾“å‡ºæœ€ç»ˆçš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œç„¶åæ˜ å°„åˆ°è¯è¡¨å¤§å°çš„çº¿æ€§å±‚ä¸Šè¿›è¡Œè§£ç ç”Ÿæˆæ–‡æœ¬ï¼›
*   æœ€ç»ˆè¿”å›ä»£è¡¨é¢„æµ‹ç»“æœçš„ logits çŸ©é˜µã€‚

 **ä¸»è¦å‚æ•°ï¼š**Â Â 

*   **d_modelï¼š**è§£ç å±‚æ¯ä¸ª token è¾“å‡ºçš„ç»´åº¦å¤§å°ï¼Œä¹‹åä¼šåšä¸€ä¸ª tgt_vocab_size å¤§å°çš„ softmax

>  **d_modelï¼š**é¢„æµ‹ä¸€ä¸ªå¾·è¯­å•è¯è¢«ç¿»è¯‘æˆè‹±è¯­ï¼Œå®ƒä¼šå¯¹åº”ä¸ºé‚£ä¸ªå•è¯ï¼Œè¿™é‡Œè¾“å…¥å°±æ˜¯ä¸€ä¸ªå•è¯åœ¨è¯è¡¨ä¸­çš„ç»´åº¦ï¼Œè¿™é‡Œçš„ç»´åº¦æ˜¯ 512ï¼Œæ‰€ä»¥åœ¨è¯è¡¨ä¸­ä¸€ä¸ªå•è¯çš„ç»´åº¦æ˜¯ 512ã€‚
> 
> å¦‚æœä¸€å¥è¯æœ‰ n ä¸ªå•è¯ï¼Œé‚£ä¹ˆåœ¨ç¿»è¯‘çš„æ•´ä¸ªè¿‡ç¨‹ä¸­å°±ä¼šè°ƒç”¨ n æ¬¡è¿™ä¸ªå…¨è¿æ¥å‡½æ•°ã€‚
> 
> ä¸¾ä¸ªæ —å­ï¼šè‹±è¯­å•è¯æœ‰ 100000 ä¸ªï¼Œé‚£ä¹ˆè¿™å„¿çš„ tgt_vocab_size å°±æ˜¯ 1000000 ä¸ªã€‚åˆ°è¾¾è¿™å„¿ï¼Œå°±å¥½åƒæ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œçœ‹è¿™ä¸ªå•è¯å±äºè¿™ 100000 ä¸ªç±»ä¸­çš„å“ªä¸€ä¸ªç±»ï¼Œæœ€åå…¨è¿æ¥åˆ†ç±»çš„ç»“æœç„¶åå†è¿›è¡Œä¸€ä¸ª softmax å°±ä¼šå¾—åˆ°è¿™ 100000 ä¸ªå•è¯æ¯ä¸ªå•è¯çš„æ¦‚ç‡ã€‚å“ªä¸ªå•è¯çš„æ¦‚ç‡æœ€å¤§ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±æŠŠè¿™ä¸ªå¾·è¯­å•è¯ç¿»è¯‘æˆé‚£ä¸ªå•è¯ã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬è¿™å„¿çš„ projection å°±æ˜¯é‚£ä¸ªå¾·è¯­å•è¯è¢«ç¿»è¯‘æˆè‹±è¯­å•è¯çš„è¯ã€‚

*   **enc_inputsï¼š**ç¼–ç ç«¯è¾“å…¥ã€‚å½¢çŠ¶ä¸º [batch_size, src_len]ï¼Œè¾“å‡ºç”±è‡ªå·±çš„å‡½æ•°å†…éƒ¨æŒ‡å®šï¼Œæƒ³è¦ä»€ä¹ˆæŒ‡å®šè¾“å‡ºä»€ä¹ˆï¼Œå¯ä»¥æ˜¯å…¨éƒ¨ tokens çš„è¾“å‡ºï¼Œå¯ä»¥æ˜¯ç‰¹å®šæ¯ä¸€å±‚çš„è¾“å‡ºï¼›ä¹Ÿå¯ä»¥æ˜¯ä¸­é—´æŸäº›å‚æ•°çš„è¾“å‡º
*   **enc_outputsï¼š**ç¼–ç ç«¯è¾“å‡ºã€‚ç¼–ç ç«¯çš„è¾“å…¥ (enc_inputs) é€šè¿‡ç¼–ç ç«¯ï¼ˆencoderï¼‰æµåˆ°ç¼–ç ç«¯çš„è¾“å‡º(enc_outputs)
*   **enc_self_attnsï¼š**Qã€K è½¬ç½®ç›¸ä¹˜å softmax çš„çŸ©é˜µå€¼ï¼Œä»£è¡¨æ¯ä¸ªå•è¯å’Œå…¶ä»–å•è¯çš„ç›¸å…³æ€§
*   **dec_outputsï¼š** è§£ç ç«¯è¾“å‡ºï¼Œç”¨äºåç»­çš„ linear æ˜ å°„
*   **dec_self_attnsï¼š** ç±»æ¯”äº enc_self_attns æ˜¯æŸ¥çœ‹æ¯ä¸ªå•è¯å¯¹è§£ç ç«¯ä¸­è¾“å…¥çš„å…¶ä½™å•è¯çš„ç›¸å…³æ€§
*   **dec_enc_attnsï¼š**è§£ç ç«¯ä¸­æ¯ä¸ªå•è¯å¯¹ encoder ä¸­æ¯ä¸ªå•è¯çš„ç›¸å…³æ€§
*   **dec_logits.viewï¼š** è¿›è¡Œ view æ“ä½œä¸»è¦æ˜¯ä¸ºäº†é€‚åº”åé¢çš„ CrossEntropyLossï¼ˆäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼‰ API çš„å‚æ•°è¦æ±‚

### 2.3 æ¨¡å‹è®­ç»ƒ

```
model=Transformer().to(device) # è°ƒç”¨Transformeræ¨¡å‹
criterion=nn.CrossEntropyLoss(ignore_index=0) # äº¤å‰ç†µæŸå¤±å‡½æ•°
optimizer=optim.SGD(model.parameters(),lr=1e-3,momentum=0.99)# ç”¨Adamçš„è¯æ•ˆæœä¸å¥½
 
for epoch in range(epochs):
    for enc_inputs,dec_inputs,dec_outputs in loader:
        """
            enc_inputs: [batch_size, src_len]
            dec_inputs: [batch_size, tgt_len]
            dec_outputs: [batch_size, tgt_len]
        """
        enc_inputs,dec_inputs,dec_outputs=enc_inputs.to(device),dec_inputs.to(device),dec_outputs.to(device)
 
        # outputs: [batch_size * tgt_len, tgt_vocab_size]
        outputs,enc_self_attns,dec_self_attns,dec_enc_attns=model(enc_inputs,dec_inputs)
 
        # dec_outputs.view(-1):[batch_size * tgt_len * tgt_vocab_size]
        loss=criterion(outputs,dec_outputs.view(-1))
        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))
 
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

è¿™é‡Œçš„æŸå¤±å‡½æ•°é‡Œé¢è®¾ç½®äº†ä¸€ä¸ªå‚æ•°**`ignore_index=0`**ï¼Œå› ä¸º "pad" è¿™ä¸ªå•è¯çš„ç´¢å¼•ä¸º 0ï¼Œè¿™æ ·è®¾ç½®ä»¥åï¼Œå°±ä¸ä¼šè®¡ç®— "pad" çš„æŸå¤±ï¼ˆå› ä¸ºæœ¬æ¥ "pad" ä¹Ÿæ²¡æœ‰æ„ä¹‰ï¼Œä¸éœ€è¦è®¡ç®—ï¼‰

ğŸš€3. [ç¼–ç å™¨](https://so.csdn.net/so/search?q=%E7%BC%96%E7%A0%81%E5%99%A8&spm=1001.2101.3001.7020)ï¼ˆEncoderï¼‰
--------------------------------------------------------------------------------------------------------

ç¼–ç å™¨ (Encoderï¼‰ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼š**è¾“å…¥**ã€**å¤šå¤´æ³¨æ„åŠ›**ã€**å‰é¦ˆç¥ç»ç½‘ç»œ**ã€‚

![](https://img-blog.csdnimg.cn/1c8c3afebedb4fd485c8711415a0be77.png)

**æµç¨‹**

*   è¾“å…¥æ–‡æœ¬çš„ç´¢å¼• tensorï¼Œç»è¿‡è¯åµŒå…¥å±‚å¾—åˆ°è¯åµŒå…¥ï¼Œç„¶åå’Œä½ç½®ç¼–ç çº¿æ€§ç›¸åŠ ä½œä¸ºè¾“å…¥å±‚çš„æœ€ç»ˆè¾“å‡ºï¼›
*   éšåï¼Œæ¯ä¸€å±‚çš„è¾“å‡ºæœ€ä¸ºä¸‹ä¸€å±‚ç¼–ç å—çš„è¾“å…¥ï¼Œåœ¨æ¯ä¸ªç¼–ç å—é‡Œè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€å‰é¦ˆç¥ç»ç½‘ç»œã€æ®‹å·®è¿æ¥ã€å±‚å½’ä¸€åŒ–ç­‰æ“ä½œï¼›
*   æœ€ç»ˆè¿”å›ç¼–ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºå’Œæ¯ä¸€å±‚çš„æ³¨æ„åŠ›æƒé‡çŸ©é˜µã€‚

### 3.1 Encoder Layerï¼šå•ä¸ªç¼–ç å™¨å±‚

ä½œä¸º **Encoder** çš„ç»„æˆå•å…ƒ, æ¯ä¸ª **Encoder Layer** å®Œæˆä¸€æ¬¡å¯¹è¾“å…¥çš„ç‰¹å¾æå–è¿‡ç¨‹, å³ç¼–ç è¿‡ç¨‹ã€‚

ç»“æ„å¦‚å›¾æ‰€ç¤ºï¼š

![](https://img-blog.csdnimg.cn/ee33c946f81c4d86b619621d33cac196.png)

```
# ---------------------------------------------------#
# EncoderLayerï¼šåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç¥ç»ç½‘ç»œ
# ---------------------------------------------------#
class EncoderLayer(nn.Module):
    def __init__(self):
        super(EncoderLayer, self).__init__()
        self.enc_self_attn = MultiHeadAttention()
        self.pos_ffn = PoswiseFeedForwardNet()
 
    def forward(self, enc_inputs, enc_self_attn_mask):
        """
        ä¸‹é¢è¿™ä¸ªå°±æ˜¯åšè‡ªæ³¨æ„åŠ›å±‚ï¼Œè¾“å…¥æ˜¯enc_inputsï¼Œå½¢çŠ¶æ˜¯[batch_size x seq_len_q x d_model]ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯æœ€åˆå§‹çš„QKVçŸ©é˜µæ˜¯ç­‰åŒäºè¿™ä¸ª
        è¾“å…¥çš„ï¼Œå»çœ‹ä¸€ä¸‹enc_self_attnå‡½æ•°.
        """
        # enc_inputs to same Q,K,V
        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)
        # enc_outputs: [batch_size x len_q x d_model]
        enc_outputs = self.pos_ffn(enc_outputs)
        return enc_outputs, attn
```

> **Encoder Layer** åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š**å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶**ï¼‹**å‰é¦ˆç¥ç»ç½‘ç»œ** 

### 3.2 Encoderï¼šç¼–ç å™¨

**Encoder** ç”¨äºå¯¹è¾“å…¥è¿›è¡ŒæŒ‡å®šçš„ç‰¹å¾æå–è¿‡ç¨‹ï¼Œä¹Ÿç§°ä¸ºç¼–ç ï¼Œç”± n ä¸ª **Encoder Layer** å±‚å †å è€Œæˆã€‚

ç»“æ„å¦‚å›¾æ‰€ç¤ºï¼š

![](https://img-blog.csdnimg.cn/4bca6c28864a41f4afaa49e7eb8c9ceb.png)

```
# -----------------------------------------------------------------------------#
# Encoderéƒ¨åˆ†åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šè¯å‘é‡embeddingï¼Œä½ç½®ç¼–ç éƒ¨åˆ†ï¼Œè‡ªæ³¨æ„åŠ›å±‚åŠåç»­çš„å‰é¦ˆç¥ç»ç½‘ç»œ
# -----------------------------------------------------------------------------#
class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        # è¿™è¡Œå…¶å®å°±æ˜¯ç”Ÿæˆä¸€ä¸ªçŸ©é˜µï¼Œå¤§å°æ˜¯: src_vocab_size * d_model
        self.src_emb = nn.Embedding(src_vocab_size, d_model)
        # ä½ç½®ç¼–ç ï¼Œè¿™é‡Œæ˜¯å›ºå®šçš„æ­£ä½™å¼¦å‡½æ•°ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ç±»ä¼¼è¯å‘é‡çš„nn.Embeddingè·å¾—ä¸€ä¸ªå¯ä»¥æ›´æ–°å­¦ä¹ çš„ä½ç½®ç¼–ç 
        self.pos_emb = PositionalEncoding(d_model)
        # ä½¿ç”¨ModuleListå¯¹å¤šä¸ªencoderè¿›è¡Œå †å ï¼Œå› ä¸ºåç»­çš„encoderå¹¶æ²¡æœ‰ä½¿ç”¨è¯å‘é‡å’Œä½ç½®ç¼–ç ï¼Œæ‰€ä»¥æŠ½ç¦»å‡ºæ¥ï¼›
        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])
 
    def forward(self, enc_inputs):
        """
        è¿™é‡Œæˆ‘ä»¬çš„enc_inputså½¢çŠ¶æ˜¯ï¼š [batch_size x source_len]
        """
        # ä¸‹é¢è¿™è¡Œä»£ç é€šè¿‡src_embè¿›è¡Œç´¢å¼•å®šä½ï¼Œenc_outputsè¾“å‡ºå½¢çŠ¶æ˜¯[batch_size, src_len, d_model]
        enc_outputs = self.src_emb(enc_inputs)
 
        # è¿™è¡Œæ˜¯ä½ç½®ç¼–ç ï¼ŒæŠŠä¸¤è€…ç›¸åŠ æ”¾åˆ°äº†pos_embå‡½æ•°é‡Œé¢
        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1)
 
        # get_attn_pad_maskæ˜¯ä¸ºäº†å¾—åˆ°å¥å­ä¸­padçš„ä½ç½®ä¿¡æ¯ï¼Œç»™åˆ°æ¨¡å‹åé¢ï¼Œåœ¨è®¡ç®—è‡ªæ³¨æ„åŠ›å’Œäº¤äº’æ³¨æ„åŠ›çš„æ—¶å€™å»æ‰padç¬¦å·çš„å½±å“
        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)
        enc_self_attns = []
        for layer in self.layers:
            # å»çœ‹EncoderLayerå±‚å‡½æ•°
            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)
            enc_self_attns.append(enc_self_attn)
        return enc_outputs, enc_self_attns
```

è¿›å…¥ Encoder åï¼Œé¦–å…ˆè¿›è¡Œ Embeddingï¼Œç„¶åè¿›è¡Œ Positional Encodingã€‚Embedding ä½¿ç”¨äº† nn.Embeddingã€‚n ä¸ª Encoder Layer å­˜æ”¾åœ¨ nn.ModuleList() é‡Œçš„åˆ—è¡¨ä¸­ã€‚Â 

> **Encoder** éƒ¨åˆ†åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼š**Word Embedding**ï¼‹**Position Embedding**ï¼‹**Multi-Head Attention å±‚åŠåç»­çš„ Feed Forward å±‚**

*   **Multi-Head Attention å±‚ï¼š** ä¸»è¦å°±æ˜¯è¿›è¡Œ attention çš„è®¡ç®—ï¼ŒQKV çš„çŸ©é˜µè¿ç®—éƒ½åœ¨è¿™é‡Œã€‚
*   **Feed Forward å±‚ï¼š**Â  å°±æ˜¯è¿›è¡Œç‰¹å¾çš„æå–ï¼Œè¿›è¡Œå‘å‰ä¼ æ’­ã€‚

### 3.3 Padding Maskï¼šå½¢æˆä¸€ä¸ªç¬¦å·çŸ©é˜µ

```
def get_attn_pad_mask(seq_q, seq_k):
    batch_size, len_q = seq_q.size()
    batch_size, len_k = seq_k.size()
    # eq(zero) is PAD token
    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k, one is masking
    # æœ€ç»ˆå¾—åˆ°çš„åº”è¯¥æ˜¯ä¸€ä¸ªæœ€ånåˆ—ä¸º1çš„çŸ©é˜µï¼Œå³Kçš„æœ€ånä¸ªtokenä¸ºPADã€‚
    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k
```

> **padding mask çš„ä½œç”¨ï¼š**
> 
> ä¸åŒ batch ä¹‹é—´å¥å­é•¿åº¦å¯ä»¥ä¸ä¸€æ ·ï¼Œä½†æ˜¯æ¯ä¸ª batch çš„é•¿åº¦å¿…é¡»æ˜¯ä¸€æ ·çš„ï¼šå› æ­¤å‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œ**ä¸å¤Ÿé•¿åº¦éœ€è¦åŠ  pad**ï¼Œä½¿å¾—å…¶é•¿åº¦å˜æˆä¸€æ ·ã€‚
> 
> æˆ‘ä»¬çœ‹ä¸€ä¸‹è¿™ä¸ªå›¾ï¼š
> 
> ![](https://img-blog.csdnimg.cn/f27b11df2e824f509d3bc058976118f9.png)
> 
> é˜´å½±éƒ¨åˆ†æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›å®ƒæ˜¯ 0ï¼Œä»¥ä¾¿åç»­çš„ softmax ç­‰æ“ä½œã€‚
> 
> padding mask çš„ä¸»è¦ä½œç”¨å°±æ˜¯**é’ˆå¯¹å¥å­ä¸å¤Ÿé•¿çš„é—®é¢˜ï¼Œæˆ‘ä»¬åŠ äº† padï¼Œå› æ­¤éœ€è¦å¯¹ pad è¿›è¡Œ é®æ© mask**ã€‚

**ä»ä»£ç è§’åº¦æ¥çœ‹ï¼š**

è¿™ä¸ªå‡½æ•°æœ€æ ¸å¿ƒçš„ä¸€å¥ä»£ç æ˜¯ **seq_k.data.eq(0)**ï¼Œè¿™å¥çš„ä½œç”¨æ˜¯**è¿”å›ä¸€ä¸ªå¤§å°å’Œ seq_k ä¸€æ ·çš„ tensor**ï¼Œåªä¸è¿‡é‡Œé¢çš„å€¼åªæœ‰ True å’Œ Falseã€‚å¦‚æœ seq_k æŸä¸ªä½ç½®çš„å€¼ç­‰äº 0ï¼Œé‚£ä¹ˆå¯¹åº”ä½ç½®å°±æ˜¯ Trueï¼Œå¦åˆ™å³ä¸º Falseã€‚

ä¸¾ä¸ªæ —å­ï¼šè¾“å…¥ä¸º seq_data = [1, 2, 3, 4, 0]ï¼Œseq_data.data.eq(0) å°±ä¼šè¿”å› [False, False, False, False, True]

**ã€æ³¨æ„ã€‘**ç”±äºåœ¨ Encoder å’Œ [Decoder](https://so.csdn.net/so/search?q=Decoder&spm=1001.2101.3001.7020) ä¸­éƒ½éœ€è¦è¿›è¡Œ maskï¼ˆå’ŒçŸ©é˜µåŸå¤§å°ä¸€æ ·ï¼Œæœ‰é—®é¢˜çš„åœ°æ–¹åŠ è´Ÿæ— ç©·ï¼‰ æ“ä½œï¼Œå› æ­¤å°±æ— æ³•ç¡®å®šè¿™ä¸ªå‡½æ•°çš„å‚æ•°ä¸­ seq_len çš„å€¼ï¼Œå¦‚æœæ˜¯åœ¨ Encoder ä¸­è°ƒç”¨çš„ï¼Œseq_len å°±ç­‰äº src_lenï¼›å¦‚æœæ˜¯åœ¨ Decoder ä¸­è°ƒç”¨çš„ï¼Œseq_len å°±æœ‰å¯èƒ½ç­‰äº src_lenï¼Œä¹Ÿæœ‰å¯èƒ½ç­‰äº tgt_lenï¼ˆå› ä¸º Decoder æœ‰ä¸¤æ¬¡ maskï¼‰ã€‚

ğŸš€4. è§£ç å™¨ï¼ˆDecoderï¼‰
-----------------

![](https://img-blog.csdnimg.cn/c86fc9844ca74465bd28b465a55cf579.png)

ä¸Šå›¾çº¢è‰²æ¡†æ¡†ä¸º Transformer çš„ **Decoder** ç»“æ„ï¼Œä¸ **Encoder** ç›¸ä¼¼ï¼Œä½†æ˜¯å­˜åœ¨ä¸€äº›åŒºåˆ«ã€‚

**Decoder** åŒ…å«ä¸¤ä¸ª **Multi-Head Attention** å±‚ã€‚

*   ç¬¬ä¸€ä¸ª Multi-Head Attention å±‚é‡‡ç”¨äº† **Masked** æ“ä½œã€‚
*   ç¬¬äºŒä¸ª Multi-Head Attention å±‚çš„ **K, V çŸ©é˜µ**ä½¿ç”¨ **Encoder** çš„**ç¼–ç ä¿¡æ¯çŸ©é˜µ C** è¿›è¡Œè®¡ç®—ï¼Œè€Œ **Q ä½¿ç”¨ä¸Šä¸€ä¸ª Decoder çš„è¾“å‡ºè®¡ç®—**ã€‚

æœ€åæœ‰ä¸€ä¸ª Softmax å±‚è®¡ç®—ä¸‹ä¸€ä¸ªç¿»è¯‘å•è¯çš„æ¦‚ç‡ã€‚

### 4.1Decoder Layerï¼šå•ä¸ªè§£ç å±‚Â 

**Decoder** æ¨¡å—ç”± 6 ä¸ª **Decoder Layer** ç»„æˆï¼Œæ¯ä¸ª Decoder Layer ç»“æ„å®Œå…¨ä¸€æ ·ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š

![](https://img-blog.csdnimg.cn/d15023a7e26d4424a7fb61083249d03c.png)

```
# -----------------------------------------------------------------------------#
# Decoder LayeråŒ…å«äº†ä¸‰ä¸ªéƒ¨åˆ†ï¼šè§£ç å™¨è‡ªæ³¨æ„åŠ›ã€â€œç¼–ç å™¨-è§£ç å™¨â€æ³¨æ„åŠ›ã€åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ
# -----------------------------------------------------------------------------#
class DecoderLayer(nn.Module):
    def __init__(self):
        super(DecoderLayer, self).__init__()
        self.dec_self_attn = MultiHeadAttention()
        self.dec_enc_attn = MultiHeadAttention()
        self.pos_ffn = PoswiseFeedForwardNet()
 
    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):
        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)
        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)
        dec_outputs = self.pos_ffn(dec_outputs)
        return dec_outputs, dec_self_attn, dec_enc_attn
```

> **Decoder Layer** åŒ…å«äº†ä¸‰ä¸ªéƒ¨åˆ†ï¼š**è§£ç å™¨è‡ªæ³¨æ„åŠ› +â€œç¼–ç å™¨ - è§£ç å™¨â€ æ³¨æ„åŠ› + åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ**

æ¯ä¸ª **Decoder Layer** ç”±ä¸‰ä¸ªå­å±‚è¿æ¥ç»“æ„ç»„æˆï¼š

*   **ç¬¬ä¸€ä¸ªå­å±‚è¿æ¥ç»“æ„ï¼š**åŒ…æ‹¬ä¸€ä¸ª **Multi-Head Attention** å’Œ **Norm å±‚**ä»¥åŠä¸€ä¸ª**æ®‹å·®è¿æ¥**ã€‚

åœ¨è®­ç»ƒæ—¶ï¼Œå› ä¸ºæœ‰ç›®æ ‡æ•°æ®å¯ç”¨ï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ª **Decoder Layer** çš„ **Multi-Head Attention** çš„è¾“å…¥æ¥è‡ªäºç›®æ ‡æ•°æ®ï¼Œä½†æ˜¯åœ¨æµ‹è¯•æ—¶ï¼Œå·²ç»æ²¡æœ‰ç›®æ ‡æ•°æ®å¯ç”¨äº†ï¼Œé‚£ä¹ˆï¼Œè¾“å…¥æ•°æ®å°±æ¥è‡ªäºæ­¤å‰åºåˆ—çš„ **Decoder** æ¨¡å—è¾“å‡ºï¼Œæ²¡æœ‰é¢„æµ‹è¿‡ï¼Œé‚£ä¹ˆå°±æ˜¯èµ·å§‹æ ‡å¿—çš„ç¼–ç ã€‚åŒæ—¶ï¼Œ**è¿™é‡Œçš„æ³¨æ„åŠ›æ˜¯è‡ªæ³¨æ„åŠ›**ï¼Œä¹Ÿå°±æ˜¯è¯´ **Qã€Kã€V éƒ½æ¥è‡ªäºç›®æ ‡æ•°æ®çŸ©é˜µå˜åŒ–å¾—æ¥**ï¼Œç„¶åè®¡ç®—æ³¨æ„åŠ›ï¼Œå¦å¤–ï¼Œè¿™é‡Œè®¡ç®—æ³¨æ„åŠ›å€¼æ—¶ï¼Œä¸€å®šä½¿ç”¨ Mask æ“ä½œã€‚åç»­çš„ 5 ä¸ª **Decoder Layer** çš„è¾“å…¥æ•°æ®æ˜¯å‰ä¸€ä¸ª **Decoder Layer** çš„è¾“å‡ºã€‚

*   Â **ç¬¬äºŒä¸ªå­å±‚è¿æ¥ç»“æ„ï¼š**åŒ…æ‹¬ä¸€ä¸ª **Multi-Head Attention** å’Œ **Norm å±‚**ä»¥åŠä¸€ä¸ª**æ®‹å·®è¿æ¥**ã€‚

**Encoder** çš„è¾“å‡ºçš„ç»“æœå°†ä¼šä½œä¸º **Kã€V** ä¼ å…¥æ¯ä¸€ä¸ª **Decoder Layer** çš„ç¬¬äºŒä¸ªå­å±‚è¿æ¥ç»“æ„ï¼Œè€Œ **Q** åˆ™æ˜¯å½“å‰ **Decoder Layer** çš„ä¸Šä¸€ä¸ªå­å±‚è¿æ¥ç»“æ„çš„è¾“å‡ºã€‚æ³¨æ„ï¼Œ**è¿™é‡Œçš„ Qã€Kã€V å·²ç»ä¸åŒæºäº†ï¼Œæ‰€ä»¥ä¸å†æ˜¯è‡ªæ³¨æ„åŠ›æœºåˆ¶**ã€‚å®Œæˆè®¡ç®—åï¼Œè¾“å‡ºç»“æœä½œä¸ºç¬¬ä¸‰ä¸ªå­å±‚è¿æ¥ç»“æ„çš„è¾“å…¥ã€‚

*   **ç¬¬ä¸‰ä¸ªå­å±‚è¿æ¥ç»“æ„ï¼š** åŒ…æ‹¬ä¸€ä¸ª**å‰é¦ˆå…¨è¿æ¥å­å±‚**å’Œ **Norm å±‚**ä»¥åŠä¸€ä¸ª**æ®‹å·®è¿æ¥**ã€‚

å®Œæˆè®¡ç®—åï¼Œè¾“å‡ºç»“æœä½œä¸ºè¾“å…¥è¿›å…¥ä¸‹ä¸€ä¸ª **Decoder Layer**ã€‚å¦‚æœæ˜¯æœ€åä¸€ä¸ª **Decoder Layer**ï¼Œé‚£ä¹ˆè¾“å‡ºç»“æœå°±ä¼ å…¥è¾“å‡ºæ¨¡å—ã€‚

### 4.2Decoderï¼šè§£ç å™¨

```
# -----------------------------------------------------------------------------#
# Decoder éƒ¨åˆ†åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šè¯å‘é‡embeddingï¼Œä½ç½®ç¼–ç éƒ¨åˆ†ï¼Œè‡ªæ³¨æ„åŠ›å±‚åŠåç»­çš„å‰é¦ˆç¥ç»ç½‘ç»œ
# -----------------------------------------------------------------------------#
class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)
        self.pos_emb = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])
 
    def forward(self, dec_inputs, enc_inputs, enc_outputs): # dec_inputs : [batch_size x target_len]
        dec_outputs = self.tgt_emb(dec_inputs)  # [batch_size, tgt_len, d_model]
        dec_outputs = self.pos_emb(dec_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, tgt_len, d_model]
 
        ## get_attn_pad_mask è‡ªæ³¨æ„åŠ›å±‚çš„æ—¶å€™çš„pad éƒ¨åˆ†
        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)
 
        ## get_attn_subsequent_mask è¿™ä¸ªåšçš„æ˜¯è‡ªæ³¨æ„å±‚çš„maskéƒ¨åˆ†ï¼Œå°±æ˜¯å½“å‰å•è¯ä¹‹åçœ‹ä¸åˆ°ï¼Œä½¿ç”¨ä¸€ä¸ªä¸Šä¸‰è§’ä¸º1çš„çŸ©é˜µ
        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)
 
        ## ä¸¤ä¸ªçŸ©é˜µç›¸åŠ ï¼Œå¤§äº0çš„ä¸º1ï¼Œä¸å¤§äº0çš„ä¸º0ï¼Œä¸º1çš„åœ¨ä¹‹åå°±ä¼šè¢«fillåˆ°æ— é™å°
        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)
 
        ## è¿™ä¸ªåšçš„æ˜¯äº¤äº’æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„maskçŸ©é˜µï¼Œencçš„è¾“å…¥æ˜¯kï¼Œæˆ‘å»çœ‹è¿™ä¸ªké‡Œé¢å“ªäº›æ˜¯padç¬¦å·ï¼Œç»™åˆ°åé¢çš„æ¨¡å‹ï¼›æ³¨æ„å“¦ï¼Œæˆ‘qè‚¯å®šä¹Ÿæ˜¯æœ‰padç¬¦å·ï¼Œä½†æ˜¯è¿™é‡Œæˆ‘ä¸åœ¨æ„çš„ï¼Œä¹‹å‰è¯´äº†å¥½å¤šæ¬¡äº†å“ˆ
        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)
 
        dec_self_attns, dec_enc_attns = [], []
        for layer in self.layers:
            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)
            dec_self_attns.append(dec_self_attn)
            dec_enc_attns.append(dec_enc_attn)
        return dec_outputs, dec_self_attns, dec_enc_attns
```

> **Decoder** éƒ¨åˆ†åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼š**Word Embedding**ï¼‹**Position Embedding**ï¼‹**Multi-Head Attention å±‚åŠåç»­çš„ Feed Forward å±‚**

**Decoder** å’Œ **Encoder** ç±»ä¼¼ï¼Œå°±æ˜¯å°† 6 ä¸ª **Decoder Layer** è¿›è¡Œå †å ã€‚ç¬¬ä¸€ä¸ª **Decoder Layer** æ¥å—ç›®æ ‡æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œåç»­çš„ **Decoder** ä½¿ç”¨å‰åºä¸€ä¸ª **Decoder Layer** çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡è¿™ç§æ–¹å¼å°† 6 ä¸ª **Decoder Layer** è¿æ¥ã€‚æœ€åä¸€ä¸ª **Decoder Layer** çš„è¾“å‡ºå°†è¿›å…¥è¾“å‡ºæ¨¡å—ã€‚Â 

### 4.3 Sequence Maskï¼šå±è”½å­åºåˆ—çš„ mask

å±è”½å­åºåˆ—çš„ mask éƒ¨åˆ†ï¼Œè¿™ä¸ªå‡½æ•°å°±æ˜¯ç”¨æ¥è¡¨ç¤º **Decoder** çš„è¾“å…¥ä¸­å“ªäº›æ˜¯æœªæ¥è¯ï¼Œä½¿ç”¨ä¸€ä¸ªä¸Šä¸‰è§’ä¸º 1 çš„çŸ©é˜µé®è”½æœªæ¥è¯ï¼Œè®©å½“å‰è¯çœ‹ä¸åˆ°æœªæ¥è¯ã€‚

![](https://img-blog.csdnimg.cn/img_convert/ac0b52b518828a0bbb67ce1db5d8cd12.jpeg)

```
def get_attn_subsequent_mask(seq):
    """
    seq: [batch_size, tgt_len]
    """
    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
    # attn_shape: [batch_size, tgt_len, tgt_len]
    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  # ç”Ÿæˆä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µ
    subsequence_mask = torch.from_numpy(subsequence_mask).byte()
    return subsequence_mask  # [batch_size, tgt_len, tgt_len]
```

ğŸš€5. ä½ç½®ç¼–ç ï¼ˆPosition Embeddingï¼‰
-----------------------------

Transformer ä¸­éœ€è¦ä½¿ç”¨ Position Embedding è¡¨ç¤ºå•è¯å‡ºç°åœ¨å¥å­ä¸­çš„ä½ç½®ã€‚å› ä¸º Transformer ä¸é‡‡ç”¨ RNN çš„ç»“æ„ï¼Œè€Œæ˜¯ä½¿ç”¨å…¨å±€ä¿¡æ¯ï¼Œå› æ­¤æ˜¯æ— æ³•æ•æ‰åˆ°åºåˆ—é¡ºåºä¿¡æ¯çš„ï¼Œä¾‹å¦‚å°† Kã€V æŒ‰è¡Œè¿›è¡Œæ‰“ä¹±ï¼Œé‚£ä¹ˆ Attention ä¹‹åçš„ç»“æœæ˜¯ä¸€æ ·çš„ã€‚ä½†æ˜¯åºåˆ—ä¿¡æ¯éå¸¸é‡è¦ï¼Œä»£è¡¨ç€å…¨å±€çš„ç»“æ„ï¼Œå› æ­¤å¿…é¡»å°†åºåˆ—çš„åˆ†è¯ç›¸å¯¹æˆ–è€…ç»å¯¹ position ä¿¡æ¯åˆ©ç”¨èµ·æ¥ã€‚  
Â 

![](https://img-blog.csdnimg.cn/9102c8a065624f86a9b1f44b56d01a2f.png)

```
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
 
        self.dropout = nn.Dropout(p=dropout)
		# ç”Ÿæˆä¸€ä¸ªå½¢çŠ¶ä¸º[max_len,d_model]çš„å…¨ä¸º0çš„tensor
        pe = torch.zeros(max_len, d_model)
        # position:[max_len,1]ï¼Œå³[5000,1]ï¼Œè¿™é‡Œæ’å…¥ä¸€ä¸ªç»´åº¦æ˜¯ä¸ºäº†åé¢èƒ½å¤Ÿè¿›è¡Œå¹¿æ’­æœºåˆ¶ç„¶åå’Œdiv_termç›´æ¥ç›¸ä¹˜
        # æ³¨æ„ï¼Œè¦ç†è§£ä¸€ä¸‹è¿™é‡Œpositionçš„ç»´åº¦ã€‚æ¯ä¸ªposéƒ½éœ€è¦512ä¸ªç¼–ç ã€‚
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        # å…±æœ‰é¡¹ï¼Œåˆ©ç”¨æŒ‡æ•°å‡½æ•°eå’Œå¯¹æ•°å‡½æ•°logå–ä¸‹æ¥ï¼Œæ–¹ä¾¿è®¡ç®—
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
 
        # è¿™é‡Œposition * div_termæœ‰å¹¿æ’­æœºåˆ¶ï¼Œå› ä¸ºdiv_termçš„å½¢çŠ¶ä¸º[d_model/2],å³[256],ç¬¦åˆå¹¿æ’­æ¡ä»¶ï¼Œå¹¿æ’­åä¸¤ä¸ªtensorç»è¿‡å¤åˆ¶ï¼Œå½¢çŠ¶éƒ½ä¼šå˜æˆ[5000,256]ï¼Œ*è¡¨ç¤ºä¸¤ä¸ªtensorå¯¹åº”ä½ç½®å¤„çš„ä¸¤ä¸ªå…ƒç´ ç›¸ä¹˜
        # è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯pe[:, 0::2]è¿™ä¸ªç”¨æ³•ï¼Œå°±æ˜¯ä»0å¼€å§‹åˆ°æœ€åé¢ï¼Œè¡¥é•¿ä¸º2ï¼Œå…¶å®ä»£è¡¨çš„å°±æ˜¯å¶æ•°ä½ç½®èµ‹å€¼ç»™pe
        pe[:, 0::2] = torch.sin(position * div_term)
        # åŒç†ï¼Œè¿™é‡Œæ˜¯å¥‡æ•°ä½ç½®
        pe[:, 1::2] = torch.cos(position * div_term)
        # ä¸Šé¢ä»£ç è·å–ä¹‹åå¾—åˆ°çš„pe:[max_len*d_model]
 
        # ä¸‹é¢è¿™ä¸ªä»£ç ä¹‹åï¼Œæˆ‘ä»¬å¾—åˆ°çš„peå½¢çŠ¶æ˜¯ï¼š[max_len*1*d_model]
        pe = pe.unsqueeze(0).transpose(0, 1)
		# å®šä¸€ä¸ªç¼“å†²åŒºï¼Œå…¶å®ç®€å•ç†è§£ä¸ºè¿™ä¸ªå‚æ•°ä¸æ›´æ–°å°±å¯ä»¥ï¼Œä½†æ˜¯å‚æ•°ä»ç„¶ä½œä¸ºæ¨¡å‹çš„å‚æ•°ä¿å­˜
        self.register_buffer('pe', pe)  
 
    def forward(self, x):
        """
        x: [seq_len, batch_size, d_model]
        """
        # è¿™é‡Œçš„self.peæ˜¯ä»ç¼“å†²åŒºé‡Œæ‹¿çš„
        # åˆ‡ç‰‡æ“ä½œï¼ŒæŠŠpeç¬¬ä¸€ç»´çš„å‰seq_lenä¸ªtensorå’Œxç›¸åŠ ï¼Œå…¶ä»–ç»´åº¦ä¸å˜
        # è¿™é‡Œå…¶å®ä¹Ÿæœ‰å¹¿æ’­æœºåˆ¶ï¼Œpe:[max_len,1,d_model]ï¼Œç¬¬äºŒç»´å¤§å°ä¸º1ï¼Œä¼šè‡ªåŠ¨æ‰©å¼ åˆ°batch_sizeå¤§å°ã€‚
        # å®ç°è¯åµŒå…¥å’Œä½ç½®ç¼–ç çš„çº¿æ€§ç›¸åŠ 
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)
```

ä½ç½®ç¼–ç çš„å®ç°ç›´æ¥å¯¹ç…§ç€å…¬å¼å†™å°±è¡Œï¼Œä¸Šé¢è¿™ä¸ªä»£ç åªæ˜¯å…¶ä¸­ä¸€ç§å®ç°æ–¹å¼ã€‚  
**ã€æ³¨æ„ã€‘**pos ä»£è¡¨çš„æ˜¯å•è¯åœ¨å¥å­ä¸­çš„ç»å¯¹ç´¢å¼•ä½ç½®ï¼Œä¾‹å¦‚ max_len æ˜¯ 128ï¼Œé‚£ä¹ˆç´¢å¼•å°±æ˜¯ä» 0,1,2,â€¦,127ï¼Œå‡è®¾ d_model æ˜¯ 512ï¼Œå³ç”¨ä¸€ä¸ª 512 ç»´ tensor æ¥ç¼–ç ä¸€ä¸ªç´¢å¼•ä½ç½®ï¼Œé‚£ä¹ˆ 0<=2i<512ï¼Œ0<=i<=255ï¼Œé‚£ä¹ˆ 2i å¯¹åº”å–å€¼å°±æ˜¯ 0,2,4â€¦510ï¼Œå³å¶æ•°ä½ç½®ï¼›2i+1 çš„å–å€¼æ˜¯ 1,3,5â€¦511ï¼Œå³å¥‡æ•°ä½ç½®ã€‚

æœ€åçš„æ–‡æœ¬åµŒå…¥è¡¨å¾æ˜¯è¯åµŒå…¥å’Œä½ç½®ç¼–ç ç›¸åŠ å¾—åˆ°ã€‚

ğŸš€6. æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰
---------------------

### 6.1Scaled DotProduct Attentionï¼šç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶

![](https://img-blog.csdnimg.cn/0055d8111cb44ebe823d83396237cf4d.png)

```
class ScaledDotProductAttention(nn.Module):
    def __init__(self):
        super(ScaledDotProductAttention, self).__init__()
 
    def forward(self, Q, K, V, attn_mask):
        # è¾“å…¥è¿›æ¥çš„ç»´åº¦åˆ†åˆ«æ˜¯Q:[batch_size x n_heads x len_q x d_k]  K:[batch_size x n_heads x len_k x d_k]  V:[batch_size x n_heads x len_k x d_v]
        # matmulæ“ä½œå³çŸ©é˜µç›¸ä¹˜
        # [batch_size x n_heads x len_q x d_k] matmul [batch_size x n_heads x d_k x len_k] -> [batch_size x n_heads x len_q x len_k]
        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
 
        # masked_fill_(mask,value)è¿™ä¸ªå‡½æ•°ï¼Œç”¨valueå¡«å……æºå‘é‡ä¸­ä¸maskä¸­å€¼ä¸º1ä½ç½®ç›¸å¯¹åº”çš„å…ƒç´ ï¼Œ
        # è¦æ±‚maskå’Œè¦å¡«å……çš„æºå‘é‡å½¢çŠ¶éœ€ä¸€è‡´
        # æŠŠè¢«maskçš„åœ°æ–¹ç½®ä¸ºæ— ç©·å°ï¼Œsoftmaxä¹‹åä¼šè¶‹è¿‘äº0ï¼ŒQä¼šå¿½è§†è¿™éƒ¨åˆ†çš„æƒé‡
        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.
        attn = nn.Softmax(dim=-1)(scores)
        context = torch.matmul(attn, V)
        # context:[batch_size,n_heads,len_q,d_k]
        # attn:[batch_size,n_heads,len_q,len_k]
        return context, attn
```

ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶ä¸»è¦åŸç†å°±æ˜¯é€šè¿‡ **Q**Â ã€**K** è®¡ç®—å‡º **scores**ï¼Œç„¶åå°† **scores** å’Œ **V è¿›è¡Œ matmul æ“ä½œï¼Œ**å³çŸ©é˜µç›¸ä¹˜ï¼Œè¿™æ ·å¾—åˆ°æ¯ä¸ªå•è¯çš„ context vectorã€‚

é¦–å…ˆå°† **Q** å’Œ **K çš„è½¬ç½®**ç›¸ä¹˜ï¼Œ**ç›¸ä¹˜ä¹‹åå¾—åˆ°çš„ scores è¿˜ä¸èƒ½ç«‹åˆ»è¿›è¡Œ softmaxï¼Œéœ€è¦å’Œ attn_mask ç›¸åŠ ï¼Œ**æŠŠä¸€äº›éœ€è¦å±è”½çš„ä¿¡æ¯å±è”½æ‰ï¼Œ**attn_mask** æ˜¯ä¸€ä¸ªä»…ç”± True å’Œ False ç»„æˆçš„ tensorï¼Œå¹¶ä¸”ä¸€å®šä¼šä¿è¯ **attn_mask** å’Œ **scores** çš„ç»´åº¦å››ä¸ªå€¼ç›¸åŒï¼ˆä¸ç„¶æ— æ³•åšå¯¹åº”ä½ç½®ç›¸åŠ ï¼‰

mask å®Œäº†ä¹‹åï¼Œå°±å¯ä»¥å¯¹ **scores** è¿›è¡Œ softmax äº†ã€‚ç„¶åå†ä¸ V ç›¸ä¹˜ï¼Œå¾—åˆ° **contextã€‚**

### 6.2MultiHead Attentionï¼šå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶

ä¸å…¶åªä½¿ç”¨å•ç‹¬ä¸€ä¸ªæ³¨æ„åŠ›æ±‡èšï¼Œ æˆ‘ä»¬å¯ä»¥ç”¨ç‹¬ç«‹å­¦ä¹ å¾—åˆ°çš„ h ç»„ï¼ˆä¸€èˆ¬ h=8ï¼‰ä¸åŒçš„çº¿æ€§æŠ•å½±æ¥å˜æ¢ Qã€K å’Œ Vã€‚

ç„¶åï¼Œè¿™ h ç»„å˜æ¢åçš„ Qã€K å’Œ V å°†å¹¶è¡Œåœ°é€åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚ æœ€åï¼Œå°†è¿™ h ä¸ªæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œ å¹¶ä¸”é€šè¿‡å¦ä¸€ä¸ªå¯ä»¥å­¦ä¹ çš„çº¿æ€§æŠ•å½±è¿›è¡Œå˜æ¢ï¼Œ ä»¥äº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚ è¿™ç§è®¾è®¡è¢«ç§°ä¸º**å¤šå¤´æ³¨æ„åŠ›ï¼ˆmultihead attentionï¼‰ã€‚**

![](https://img-blog.csdnimg.cn/c3a8420693c641bb80be1f96b321dec8.png)

```
class MultiHeadAttention(nn.Module):
    def __init__(self):
        super(MultiHeadAttention, self).__init__()
        # Wq,Wk,Wvå…¶å®å°±æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ï¼Œç”¨æ¥å°†è¾“å…¥æ˜ å°„ä¸ºQã€Kã€V
        # è¿™é‡Œè¾“å‡ºæ˜¯d_k * n_headsï¼Œå› ä¸ºæ˜¯å…ˆæ˜ å°„ï¼Œååˆ†å¤´ã€‚
        self.W_Q = nn.Linear(d_model, d_k * n_heads) 
        self.W_K = nn.Linear(d_model, d_k * n_heads)
        self.W_V = nn.Linear(d_model, d_v * n_heads)
        self.linear = nn.Linear(n_heads * d_v, d_model)
        self.layer_norm = nn.LayerNorm(d_model)
 
    def forward(self, Q, K, V, attn_mask):
        # attn_mask:[batch_size,len_q,len_k]
        # è¾“å…¥çš„æ•°æ®å½¢çŠ¶ï¼š Q: [batch_size x len_q x d_model], K: [batch_size x len_k x d_model], 
        # V: [batch_size x len_k x d_model]
        residual, batch_size = Q, Q.size(0)
        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)
 
        # åˆ†å¤´ï¼›ä¸€å®šè¦æ³¨æ„çš„æ˜¯qå’Œkåˆ†å¤´ä¹‹åç»´åº¦æ˜¯ä¸€è‡´çš„ï¼Œæ‰€ä»¥ä¸€çœ‹è¿™é‡Œéƒ½æ˜¯d_k
        # q_s: [batch_size x n_heads x len_q x d_k]
        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)
        # k_s: [batch_size x n_heads x len_k x d_k]
        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)
        # v_s: [batch_size x n_heads x len_k x d_v]
        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)
 
        # attn_mask:[batch_size x len_q x len_k] ---> [batch_size x n_heads x len_q x len_k]
        # å°±æ˜¯æŠŠpadä¿¡æ¯å¤åˆ¶nä»½ï¼Œé‡å¤åˆ°nä¸ªå¤´ä¸Šä»¥ä¾¿è®¡ç®—å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
 
        # è®¡ç®—ScaledDotProductAttention
        # å¾—åˆ°çš„ç»“æœæœ‰ä¸¤ä¸ªï¼šcontext: [batch_size x n_heads x len_q x d_v],
        # attn: [batch_size x n_heads x len_q x len_k]
        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)
        # è¿™é‡Œå®é™…ä¸Šåœ¨æ‹¼æ¥nä¸ªå¤´ï¼ŒæŠŠnä¸ªå¤´çš„åŠ æƒæ³¨æ„åŠ›è¾“å‡ºæ‹¼æ¥ï¼Œç„¶åè¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼Œcontextå˜æˆ
        # [batch_size,len_q,n_heads*d_v]ã€‚è¿™é‡Œcontextéœ€è¦è¿›è¡Œcontiguousï¼Œå› ä¸ºtransposeåæºtensorå˜æˆä¸è¿ç»­çš„
        # äº†ï¼Œviewæ“ä½œéœ€è¦è¿ç»­çš„tensorã€‚
        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v)
        output = self.linear(context)
        # è¿‡æ®‹å·®ã€LNï¼Œè¾“å‡ºoutput: [batch_size x len_q x d_model]å’Œè¿™ä¸€å±‚çš„åŠ æƒæ³¨æ„åŠ›è¡¨å¾å‘é‡
        return self.layer_norm(output + residual), attn
```

ä»£ç ä¸­æœ‰ä¸‰å¤„åœ°æ–¹è°ƒç”¨ **MultiHeadAttention()ï¼š**

*   **Encoder Layer** è°ƒç”¨ä¸€æ¬¡ï¼Œä¼ å…¥çš„ **input_Q**ã€**input_K**ã€**input_V** å…¨éƒ¨éƒ½æ˜¯ **enc_inputs**ï¼›
*   **Decoder Layer** ä¸­ä¸¤æ¬¡è°ƒç”¨ï¼š
    *   ç¬¬ä¸€æ¬¡ä¼ å…¥çš„å…¨æ˜¯ **dec_inputs**ï¼Œ
    *   ç¬¬äºŒæ¬¡ä¼ å…¥çš„åˆ†åˆ«æ˜¯ **dec_outputsï¼Œenc_outputsï¼Œenc_outputs**

> è¿™é‡Œéœ€è¦æ³¨æ„ä¸€ä¸‹ï¼šä¸ºå•¥éƒ½æ˜¯ d_k è€Œä¸æ˜¯ d_q å‘¢ï¼Ÿ![](https://img-blog.csdnimg.cn/11499ed5b5e84576935026915543e802.png)
> 
> æˆ‘ä»¬è¦æ³¨æ„çš„æ˜¯ q å’Œ k åˆ†å¤´ä¹‹åç»´åº¦æ˜¯ä¸€è‡´çš„ï¼Œæ‰€ä»¥è¿™é‡Œéƒ½æ˜¯ dk

ğŸš€7. å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆPoswiseFeedForwardï¼‰
-------------------------------

å®Œæˆå¤šå¤´æ³¨æ„åŠ›è®¡ç®—åï¼Œè€ƒè™‘åˆ°æ­¤å‰ä¸€ç³»åˆ—æ“ä½œå¯¹å¤æ‚è¿‡ç¨‹çš„æ‹Ÿåˆç¨‹åº¦å¯èƒ½ä¸è¶³ï¼Œæ‰€ä»¥é€šè¿‡å¢åŠ å…¨è¿æ¥å±‚æ¥å¢å¼ºæ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ã€‚Â 

æœ‰ä¸¤ç§å®ç°æ–¹å¼ï¼šä¸€ç§æ˜¯é€šè¿‡å·ç§¯çš„æ–¹å¼å®ç°ï¼Œä¸€ç§æ˜¯é€šè¿‡çº¿æ€§å±‚å®ç°ã€‚äºŒè€…çš„åŒºåˆ«é™¤äº†åŸç†ä¸Šï¼Œè¿˜æœ‰ä»£ç ç»†èŠ‚ä¸Šã€‚

ä¸¾ä¸ªæ —å­ï¼š

*   ç¬¬ä¸€ç§å·ç§¯æ–¹å¼å®ç°è¦æ±‚è¾“å…¥å¿…é¡»æ˜¯ **[batch_size,channel,length]**ï¼Œå¿…é¡»æ˜¯**ä¸‰ç»´ tensor**
*   ç¬¬äºŒç§çº¿æ€§å±‚æ–¹å¼å®ç°è¦æ±‚è¾“å…¥æ˜¯ **[batch_size,*,d_model]**ï¼Œå¯ä»¥æœ‰**å¤šä¸ªç»´åº¦**

#### 7.1 å®ç°æ–¹å¼ 1ï¼šConv1d

```
class PoswiseFeedForwardNet(nn.Module):
    def __init__(self):
        super(PoswiseFeedForwardNet, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)
        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)
        self.layer_norm = nn.LayerNorm(d_model)
 
    def forward(self, inputs):
        residual = inputs # inputs : [batch_size, len_q, d_model]
        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))
        output = self.conv2(output).transpose(1, 2)
        return self.layer_norm(output + residual)
```

###  **7.2 å®ç°æ–¹å¼ 2ï¼šLinear**

```
class PoswiseFeedForwardNet(nn.Module):
    def __init__(self):
        super(PoswiseFeedForwardNet, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(d_model, d_ff, bias=False),
            nn.ReLU(),
            nn.Linear(d_ff, d_model, bias=False))
        
    def forward(self, inputs):              # inputs: [batch_size, seq_len, d_model]
        residual = inputs
        output = self.fc(inputs)
        return nn.LayerNorm(d_model).(output + residual)   # [batch_size, seq_len, d_model]
```

è¿™ä¸ªæ–¹å¼æ¯”è¾ƒå¥½ç†è§£ï¼Œå°±æ˜¯åšä¸¤æ¬¡çº¿æ€§å˜æ¢ï¼Œæ®‹å·®è¿æ¥åå†è·Ÿä¸€ä¸ª Layer Norm

> **Layer Norm çš„ä½œç”¨ï¼š**å¯¹ x å½’ä¸€åŒ–ï¼Œä½¿ x çš„å‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1

ä»¥ä¸Šå°±æ˜¯ transformer ä»£ç çš„è§£è¯»ã€‚

æ›´å¤šè¯¦ç»†è§£è¯»è¿˜è¦çœ‹å„ä½å¤§ä½¬çš„ï¼š

b ç«™ï¼š[Transformer ä»£ç  (æºç  Pytorch ç‰ˆæœ¬) ä»é›¶è§£è¯»(Pytorch ç‰ˆæœ¬ï¼‰_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1dR4y1E7aL?p=1&vd_source=84352d0824b330075f0cb61978ba4fbb "Transformerä»£ç (æºç Pytorchç‰ˆæœ¬)ä»é›¶è§£è¯»(Pytorchç‰ˆæœ¬ï¼‰_å“”å“©å“”å“©_bilibili")

 [æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨ Pytorch ä»£ç å®ç° Transformer æ¨¡å‹_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1vf4y1n7k2/?spm_id_from=333.788.recommend_more_video.1&vd_source=84352d0824b330075f0cb61978ba4fbb "Â  Â  Â  Â  Â æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨Pytorchä»£ç å®ç°Transformeræ¨¡å‹_å“”å“©å“”å“©_bilibili")

CSDNï¼š[Transformer çš„ PyTorch å®ç°ï¼ˆè¶…è¯¦ç»†ï¼‰](https://mathor.blog.csdn.net/article/details/107352273?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-107352273-blog-126187598.235%5Ev31%5Epc_relevant_default_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-107352273-blog-126187598.235%5Ev31%5Epc_relevant_default_base&utm_relevant_index=2 "Transformerçš„PyTorchå®ç°ï¼ˆè¶…è¯¦ç»†ï¼‰")Â 

![](https://img-blog.csdnimg.cn/e012ccba0b5d48a59e42ecf4756cfb91.gif)